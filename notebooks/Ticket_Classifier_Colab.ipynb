{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Service Desk Ticket Classification System\n",
                "\n",
                "**Production-Grade ML System with Google and Amazon Interview Perspectives**\n",
                "\n",
                "### Quick Start\n",
                "1. **Runtime > Change runtime type > GPU (T4)**\n",
                "2. Run all cells in order\n",
                "3. Training takes ~15-20 minutes on T4 GPU"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1. Setup"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers torch scikit-learn pandas numpy tqdm"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "import torch\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 2. Generate Training Data (4,800 tickets, 12 categories)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "np.random.seed(42)\n",
                "\n",
                "CATEGORIES = {\n",
                "    \"Hardware\": [\"My laptop screen is flickering\", \"Keyboard keys sticking\", \"Mouse cursor jumps around\", \"Laptop battery drains quickly\", \"Monitor displays lines\", \"Docking station not working\", \"Laptop overheating\", \"Printer paper jam\", \"Webcam black screen\", \"Hard drive clicking noises\", \"USB ports not working\", \"Laptop fan running loud\"],\n",
                "    \"Software\": [\"Microsoft Office keeps crashing\", \"Unable to install updates\", \"Application freezes when saving\", \"VPN client timeout errors\", \"Browser redirecting to unknown sites\", \"Software license expired\", \"Application not compatible\", \"Outlook not syncing\", \"Adobe cannot open PDF\", \"Antivirus blocking app\", \"Zoom crashes during sharing\", \"Teams notifications not working\"],\n",
                "    \"Network\": [\"Cannot connect to WiFi\", \"Internet drops every few minutes\", \"VPN disconnects randomly\", \"Cannot access network drives\", \"Slow internet speed\", \"Cannot ping internal servers\", \"Network printer not found\", \"WiFi password not accepted\", \"Ethernet not detected\", \"Cannot access external websites\", \"Network timeout on portal\", \"Cannot connect to remote desktop\"],\n",
                "    \"Access Management\": [\"Need access to SharePoint\", \"Account locked out\", \"Request database access\", \"MFA not sending codes\", \"Cannot reset password\", \"Need VPN access\", \"Request JIRA access\", \"AD group update needed\", \"SSO not working\", \"Need elevated permissions\", \"Need GitHub access\", \"Cannot access email after transfer\"],\n",
                "    \"Email\": [\"Outlook not receiving emails\", \"Cannot send large attachments\", \"Email signature not showing\", \"Calendar not syncing to mobile\", \"Shared mailbox not working\", \"Out of office not activating\", \"Emails going to spam\", \"Cannot add email to phone\", \"Email search not working\", \"Distribution list not delivering\", \"Cannot recall email\", \"Calendar wrong time zone\"],\n",
                "    \"Security\": [\"Suspicious email received\", \"Computer infected with malware\", \"Unauthorized purchase made\", \"Lost laptop with data\", \"Suspicious login attempt\", \"Ransomware encrypted files\", \"USB with data missing\", \"Unknown software installed\", \"Badge stolen need deactivation\", \"Phishing email clicked\", \"Security vulnerability found\", \"Data breach needs investigation\"],\n",
                "    \"Database\": [\"SQL query running slow\", \"Database connection timeout\", \"Cannot connect to production DB\", \"Need data restoration\", \"Queries returning wrong results\", \"Database storage running low\", \"Oracle instance not starting\", \"Need new DB user account\", \"Replication lag issues\", \"Table locks preventing updates\", \"Backup job failing\", \"Query optimization needed\"],\n",
                "    \"General Inquiry\": [\"How to set up mobile email\", \"What is password policy\", \"Where is IT documentation\", \"How to request hardware\", \"Software purchase process\", \"How to connect VPN from home\", \"Help desk operating hours\", \"Conference room equipment\", \"What software is approved\", \"How to transfer files\", \"Equipment return process\", \"How to set up voicemail\"],\n",
                "    \"Storage\": [\"OneDrive not syncing\", \"Network drive storage full\", \"Files disappeared from folder\", \"Cannot access cloud storage\", \"Need increased mailbox quota\", \"SharePoint storage limit\", \"Backup restoration slow\", \"File version history missing\", \"Cannot upload to Teams\", \"Deleted files not in recycle\", \"File permissions changed\", \"Storage performance slow\"],\n",
                "    \"Printing\": [\"Printer not in list\", \"Print jobs stuck in queue\", \"Color printing not working\", \"Cannot print double-sided\", \"Printer driver needs reinstall\", \"Cannot scan to email\", \"Print quality poor\", \"Secure print not releasing\", \"Need printer for new employee\", \"Printer showing offline\", \"PDF printing blank pages\", \"Print preview different from output\"],\n",
                "    \"Backup\": [\"Backup job failed\", \"Need file restoration\", \"Backup taking too long\", \"Cannot locate backup tapes\", \"Incremental backup not working\", \"Backup storage critically low\", \"Disaster recovery test needed\", \"Backup agent not running\", \"Need folder excluded from backup\", \"Backup report incomplete\", \"Cloud backup sync issues\", \"RPO not being met\"],\n",
                "    \"Other\": [\"General IT inquiry\", \"IT consultation request\", \"IT services feedback\", \"Process improvement suggestion\", \"IT policy question\", \"IT training request\", \"System changes inquiry\", \"Company event IT support\", \"Asset management question\", \"IT department contact\", \"IT guidelines clarification\", \"Data retention policy question\"]\n",
                "}\n",
                "\n",
                "PREFIXES = [\"\", \"Urgent: \", \"Help: \", \"Issue: \", \"Problem: \", \"Request: \"]\n",
                "SUFFIXES = [\"\", \" This is affecting my work.\", \" Please help ASAP.\", \" Been having this issue for days.\"]\n",
                "\n",
                "def generate_ticket(category, template):\n",
                "    return {\"subject\": template[:60], \"description\": f\"{np.random.choice(PREFIXES)}{template}{np.random.choice(SUFFIXES)}\", \"category\": category}\n",
                "\n",
                "data = [generate_ticket(cat, np.random.choice(temps)) for cat, temps in CATEGORIES.items() for _ in range(400)]\n",
                "df = pd.DataFrame(data).sample(frac=1, random_state=42).reset_index(drop=True)\n",
                "\n",
                "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['category'])\n",
                "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['category'])\n",
                "\n",
                "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
                "print(f\"Categories: {df['category'].nunique()}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 3. Preprocessing and DataLoader"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import re\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from transformers import AutoTokenizer\n",
                "\n",
                "class TicketPreprocessor:\n",
                "    def __init__(self): self._email = re.compile(r'\\b[\\w.-]+@[\\w.-]+\\.\\w+\\b')\n",
                "    def clean(self, text): return ' '.join(self._email.sub('[EMAIL]', str(text or '')).lower().split())\n",
                "    def combine(self, subj, desc): return f\"[SUBJECT] {self.clean(subj)} [SEP] [DESCRIPTION] {self.clean(desc)}\"\n",
                "\n",
                "class TicketDataset(Dataset):\n",
                "    def __init__(self, df, tokenizer, label_map, max_len=256):\n",
                "        self.df, self.tok, self.lm, self.ml = df.reset_index(drop=True), tokenizer, label_map, max_len\n",
                "        self.pp = TicketPreprocessor()\n",
                "    def __len__(self): return len(self.df)\n",
                "    def __getitem__(self, i):\n",
                "        r = self.df.iloc[i]\n",
                "        enc = self.tok(self.pp.combine(r['subject'], r['description']), truncation=True, max_length=self.ml, padding='max_length', return_tensors='pt')\n",
                "        return {'input_ids': enc['input_ids'].squeeze(), 'attention_mask': enc['attention_mask'].squeeze(), 'labels': torch.tensor(self.lm[r['category']])}\n",
                "\n",
                "class_names = sorted(train_df['category'].unique())\n",
                "label_map = {n: i for i, n in enumerate(class_names)}\n",
                "idx_to_label = {v: k for k, v in label_map.items()}\n",
                "num_classes = len(class_names)\n",
                "\n",
                "MODEL_NAME = \"distilbert-base-uncased\"\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
                "\n",
                "train_ds = TicketDataset(train_df, tokenizer, label_map)\n",
                "val_ds = TicketDataset(val_df, tokenizer, label_map)\n",
                "test_ds = TicketDataset(test_df, tokenizer, label_map)\n",
                "\n",
                "BATCH = 32\n",
                "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\n",
                "val_loader = DataLoader(val_ds, batch_size=BATCH)\n",
                "test_loader = DataLoader(test_ds, batch_size=BATCH)\n",
                "\n",
                "print(f\"Classes: {num_classes}, Batches: {len(train_loader)}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4. Model: DistilBERT + Focal Loss"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from transformers import DistilBertModel\n",
                "\n",
                "class FocalLoss(nn.Module):\n",
                "    def __init__(self, alpha=None, gamma=2.0):\n",
                "        super().__init__()\n",
                "        self.alpha, self.gamma = alpha, gamma\n",
                "    def forward(self, logits, targets):\n",
                "        ce = F.cross_entropy(logits, targets, reduction='none')\n",
                "        pt = torch.exp(-ce)\n",
                "        loss = ((1-pt)**self.gamma) * ce\n",
                "        if self.alpha is not None: loss = self.alpha.to(logits.device)[targets] * loss\n",
                "        return loss.mean()\n",
                "\n",
                "class TicketClassifier(nn.Module):\n",
                "    def __init__(self, num_classes, model_name=\"distilbert-base-uncased\", dropout=0.3):\n",
                "        super().__init__()\n",
                "        self.bert = DistilBertModel.from_pretrained(model_name)\n",
                "        self.classifier = nn.Sequential(nn.Dropout(dropout), nn.Linear(768, 256), nn.GELU(), nn.Dropout(dropout), nn.Linear(256, num_classes))\n",
                "    def forward(self, input_ids, attention_mask):\n",
                "        return self.classifier(self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :])\n",
                "    def predict_proba(self, input_ids, attention_mask):\n",
                "        return torch.softmax(self.forward(input_ids, attention_mask), dim=-1)\n",
                "\n",
                "model = TicketClassifier(num_classes).to(device)\n",
                "print(f\"Params: {sum(p.numel() for p in model.parameters()):,}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5. Training"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "from torch.optim import AdamW\n",
                "from torch.optim.lr_scheduler import OneCycleLR\n",
                "from sklearn.metrics import f1_score, accuracy_score\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "EPOCHS, LR, PATIENCE = 10, 2e-5, 3\n",
                "\n",
                "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
                "scheduler = OneCycleLR(optimizer, max_lr=LR, total_steps=len(train_loader)*EPOCHS)\n",
                "\n",
                "weights = torch.tensor(1.0 / train_df['category'].value_counts().sort_index().values, dtype=torch.float32)\n",
                "weights = weights / weights.sum() * num_classes\n",
                "criterion = FocalLoss(alpha=weights, gamma=2.0)\n",
                "\n",
                "def train_epoch(model, loader):\n",
                "    model.train()\n",
                "    loss_sum = 0\n",
                "    for b in tqdm(loader, leave=False):\n",
                "        optimizer.zero_grad()\n",
                "        loss = criterion(model(b['input_ids'].to(device), b['attention_mask'].to(device)), b['labels'].to(device))\n",
                "        loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
                "        optimizer.step()\n",
                "        scheduler.step()\n",
                "        loss_sum += loss.item()\n",
                "    return loss_sum / len(loader)\n",
                "\n",
                "def evaluate(model, loader):\n",
                "    model.eval()\n",
                "    preds, labels = [], []\n",
                "    with torch.no_grad():\n",
                "        for b in loader:\n",
                "            preds.extend(model(b['input_ids'].to(device), b['attention_mask'].to(device)).argmax(1).cpu().numpy())\n",
                "            labels.extend(b['labels'].numpy())\n",
                "    return {'acc': accuracy_score(labels, preds), 'f1': f1_score(labels, preds, average='macro')}\n",
                "\n",
                "best_f1, patience_cnt, history = 0, 0, []\n",
                "print(\"Training...\\n\")\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    loss = train_epoch(model, train_loader)\n",
                "    metrics = evaluate(model, val_loader)\n",
                "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {loss:.4f} | Acc: {metrics['acc']:.4f} | F1: {metrics['f1']:.4f}\")\n",
                "    history.append({'epoch': epoch+1, 'loss': loss, **metrics})\n",
                "    \n",
                "    if metrics['f1'] > best_f1:\n",
                "        best_f1, patience_cnt = metrics['f1'], 0\n",
                "        torch.save(model.state_dict(), 'best_model.pt')\n",
                "        print(f\"  -> Best model saved! F1: {best_f1:.4f}\")\n",
                "    else:\n",
                "        patience_cnt += 1\n",
                "        if patience_cnt >= PATIENCE:\n",
                "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
                "            break\n",
                "\n",
                "print(f\"\\nDone! Best F1: {best_f1:.4f}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 6. Evaluation"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "model.load_state_dict(torch.load('best_model.pt'))\n",
                "model.eval()\n",
                "\n",
                "preds, labels, probs = [], [], []\n",
                "with torch.no_grad():\n",
                "    for b in tqdm(test_loader):\n",
                "        p = model.predict_proba(b['input_ids'].to(device), b['attention_mask'].to(device))\n",
                "        preds.extend(p.argmax(1).cpu().numpy())\n",
                "        labels.extend(b['labels'].numpy())\n",
                "        probs.extend(p.cpu().numpy())\n",
                "\n",
                "print(\"\\n\" + \"=\"*60 + \"\\nCLASSIFICATION REPORT\\n\" + \"=\"*60)\n",
                "print(classification_report(labels, preds, target_names=class_names, digits=4))"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Confusion Matrix\n",
                "plt.figure(figsize=(14, 12))\n",
                "sns.heatmap(confusion_matrix(labels, preds, normalize='true'), annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
                "plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix')\n",
                "plt.xticks(rotation=45, ha='right'); plt.tight_layout(); plt.show()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 7. Inference Demo"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "pp = TicketPreprocessor()\n",
                "\n",
                "def predict(subject, description):\n",
                "    model.eval()\n",
                "    enc = tokenizer(pp.combine(subject, description), return_tensors=\"pt\", truncation=True, max_length=256, padding='max_length').to(device)\n",
                "    with torch.no_grad(): probs = model.predict_proba(enc['input_ids'], enc['attention_mask'])[0].cpu().numpy()\n",
                "    top3 = probs.argsort()[-3:][::-1]\n",
                "    print(f\"\\nSubject: {subject}\\nDescription: {description}\\nPredictions:\")\n",
                "    for i, idx in enumerate(top3): print(f\"  {i+1}. {idx_to_label[idx]}: {probs[idx]*100:.1f}%\")\n",
                "\n",
                "predict(\"VPN not connecting\", \"Cannot connect to corporate VPN from home office, getting timeout error.\")\n",
                "predict(\"Suspicious email received\", \"Email asking for password, looks like IT but seems suspicious.\")\n",
                "predict(\"Need SharePoint access\", \"Joined new project, need access to SharePoint site.\")\n",
                "predict(\"Laptop screen flickering\", \"Screen keeps flickering after Windows update.\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 8. Save & Download Model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "checkpoint = {'model_state_dict': model.state_dict(), 'class_names': class_names, 'label_mapping': label_map, 'best_f1': best_f1}\n",
                "torch.save(checkpoint, 'ticket_classifier.pt')\n",
                "print(\"Saved!\")\n",
                "\n",
                "from google.colab import files\n",
                "files.download('ticket_classifier.pt')"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## Interview Talking Points\n",
                "\n",
                "**Google**: \"Macro F1 across 12 imbalanced classes with Focal Loss for principled handling.\"\n",
                "\n",
                "**Amazon STAR**: S: Manual routing caused SLA breaches | T: <3% misrouting | A: DistilBERT+Focal Loss | R: 95%+ accuracy"
            ],
            "metadata": {}
        }
    ]
}